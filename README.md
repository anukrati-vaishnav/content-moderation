# Automated Content-Moderation
This project focuses on leveraging Artificial Intelligence (AI) and Natural Language Processing
(NLP) to detect and combat toxicity in online comments. The project aims to create an automated content moderation system that ensures safer
and more inclusive online spaces by employing machine learning techniques. The analysis is based on a dataset of user-generated comments
labeled with various toxicity attributes, such as toxic, severe toxic, insult, obscene, and others.

